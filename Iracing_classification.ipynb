{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1_qWyCblfF8B7RXdqjIl202iKnbosspKp",
      "authorship_tag": "ABX9TyNH55zggfbNcObj4lRNQhE0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TomazFilgueira/UFRN-ML-2025-1-AutoParts_Classification/blob/main/Iracing_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "y8oXM6PjM9nt"
      },
      "outputs": [],
      "source": [
        "# Import standard libraries for randomness, deep copying, and numerical operations\n",
        "import random\n",
        "import numpy as np\n",
        "from copy import deepcopy\n",
        "\n",
        "# Import libraries for image processing and data manipulation\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "\n",
        "# Import PyTorch core and utilities for deep learning\n",
        "import torch\n",
        "import torch.optim as optim  # Optimization algorithms\n",
        "import torch.nn as nn  # Neural network modules\n",
        "import torch.nn.functional as F  # Functional API for non-parametric operations\n",
        "\n",
        "# Import PyTorch utilities for data loading and transformations\n",
        "from torch.utils.data import DataLoader, Dataset, random_split, WeightedRandomSampler\n",
        "from torchvision.transforms.v2 import Compose, ToImage, Normalize, ToPILImage, Resize, ToDtype\n",
        "\n",
        "# Import dataset handling and learning rate schedulers\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, MultiStepLR, CyclicLR, LambdaLR\n",
        "\n",
        "# Import visualization and web utilities\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "import zipfile\n",
        "import os\n",
        "import errno\n",
        "\n",
        "# Set matplotlib style for better visuals\n",
        "plt.style.use('fivethirtyeight')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Architecture(object):\n",
        "    def __init__(self, model, loss_fn, optimizer):\n",
        "        # Here we define the attributes of our class\n",
        "\n",
        "        # We start by storing the arguments as attributes\n",
        "        # to use them later\n",
        "        self.model = model\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        # Let's send the model to the specified device right away\n",
        "        self.model.to(self.device)\n",
        "\n",
        "        # These attributes are defined here, but since they are\n",
        "        # not informed at the moment of creation, we keep them None\n",
        "        self.train_loader = None\n",
        "        self.val_loader = None\n",
        "\n",
        "        # These attributes are going to be computed internally\n",
        "        self.losses = []\n",
        "        self.val_losses = []\n",
        "        self.total_epochs = 0\n",
        "\n",
        "        # Creates the train_step function for our model,\n",
        "        # loss function and optimizer\n",
        "        # Note: there are NO ARGS there! It makes use of the class\n",
        "        # attributes directly\n",
        "        self.train_step_fn = self._make_train_step_fn()\n",
        "        # Creates the val_step function for our model and loss\n",
        "        self.val_step_fn = self._make_val_step_fn()\n",
        "\n",
        "        # for hook purposes\n",
        "        self.handles = {}\n",
        "        self.visualization = {}\n",
        "\n",
        "    def to(self, device):\n",
        "        # This method allows the user to specify a different device\n",
        "        # It sets the corresponding attribute (to be used later in\n",
        "        # the mini-batches) and sends the model to the device\n",
        "        try:\n",
        "            self.device = device\n",
        "            self.model.to(self.device)\n",
        "        except RuntimeError:\n",
        "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "            print(f\"Couldn't send it to {device}, sending it to {self.device} instead.\")\n",
        "            self.model.to(self.device)\n",
        "\n",
        "    def set_loaders(self, train_loader, val_loader=None):\n",
        "        # This method allows the user to define which train_loader (and val_loader, optionally) to use\n",
        "        # Both loaders are then assigned to attributes of the class\n",
        "        # So they can be referred to later\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "\n",
        "    def _make_train_step_fn(self):\n",
        "        # This method does not need ARGS... it can refer to\n",
        "        # the attributes: self.model, self.loss_fn and self.optimizer\n",
        "\n",
        "        # Builds function that performs a step in the train loop\n",
        "        def perform_train_step_fn(x, y):\n",
        "            # Sets model to TRAIN mode\n",
        "            self.model.train()\n",
        "\n",
        "            # Step 1 - Computes our model's predicted output - forward pass\n",
        "            yhat = self.model(x)\n",
        "            # Step 2 - Computes the loss\n",
        "            loss = self.loss_fn(yhat, y)\n",
        "            # Step 3 - Computes gradients for both \"a\" and \"b\" parameters\n",
        "            loss.backward()\n",
        "            # Step 4 - Updates parameters using gradients and the learning rate\n",
        "            self.optimizer.step()\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            # Returns the loss\n",
        "            return loss.item()\n",
        "\n",
        "        # Returns the function that will be called inside the train loop\n",
        "        return perform_train_step_fn\n",
        "\n",
        "    def _make_val_step_fn(self):\n",
        "        # Builds function that performs a step in the validation loop\n",
        "        def perform_val_step_fn(x, y):\n",
        "            # Sets model to EVAL mode\n",
        "            self.model.eval()\n",
        "\n",
        "            # Step 1 - Computes our model's predicted output - forward pass\n",
        "            yhat = self.model(x)\n",
        "            # Step 2 - Computes the loss\n",
        "            loss = self.loss_fn(yhat, y)\n",
        "            # There is no need to compute Steps 3 and 4, since we don't update parameters during evaluation\n",
        "            return loss.item()\n",
        "\n",
        "        return perform_val_step_fn\n",
        "\n",
        "    def _mini_batch(self, validation=False):\n",
        "        # The mini-batch can be used with both loaders\n",
        "        # The argument `validation`defines which loader and\n",
        "        # corresponding step function is going to be used\n",
        "        if validation:\n",
        "            data_loader = self.val_loader\n",
        "            step_fn = self.val_step_fn\n",
        "        else:\n",
        "            data_loader = self.train_loader\n",
        "            step_fn = self.train_step_fn\n",
        "\n",
        "        if data_loader is None:\n",
        "            return None\n",
        "\n",
        "        # Once the data loader and step function, this is the same\n",
        "        # mini-batch loop we had before\n",
        "        mini_batch_losses = []\n",
        "        for x_batch, y_batch in data_loader:\n",
        "            x_batch = x_batch.to(self.device)\n",
        "            y_batch = y_batch.to(self.device)\n",
        "\n",
        "            mini_batch_loss = step_fn(x_batch, y_batch)\n",
        "            mini_batch_losses.append(mini_batch_loss)\n",
        "\n",
        "        loss = np.mean(mini_batch_losses)\n",
        "        return loss\n",
        "\n",
        "    # this function was updated in this class\n",
        "    def set_seed(self, seed=42):\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "        torch.manual_seed(seed)\n",
        "        np.random.seed(seed)\n",
        "        random.seed(seed)\n",
        "        try:\n",
        "            self.train_loader.sampler.generator.manual_seed(seed)\n",
        "        except AttributeError:\n",
        "            pass\n",
        "\n",
        "    def train(self, n_epochs, seed=42):\n",
        "        # To ensure reproducibility of the training process\n",
        "        self.set_seed(seed)\n",
        "\n",
        "        for epoch in range(n_epochs):\n",
        "            # Keeps track of the numbers of epochs\n",
        "            # by updating the corresponding attribute\n",
        "            self.total_epochs += 1\n",
        "\n",
        "            # inner loop\n",
        "            # Performs training using mini-batches\n",
        "            loss = self._mini_batch(validation=False)\n",
        "            self.losses.append(loss)\n",
        "\n",
        "            # VALIDATION\n",
        "            # no gradients in validation!\n",
        "            with torch.no_grad():\n",
        "                # Performs evaluation using mini-batches\n",
        "                val_loss = self._mini_batch(validation=True)\n",
        "                self.val_losses.append(val_loss)\n",
        "\n",
        "    def save_checkpoint(self, filename):\n",
        "        # Builds dictionary with all elements for resuming training\n",
        "        checkpoint = {'epoch': self.total_epochs,\n",
        "                      'model_state_dict': self.model.state_dict(),\n",
        "                      'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "                      'loss': self.losses,\n",
        "                      'val_loss': self.val_losses}\n",
        "\n",
        "        torch.save(checkpoint, filename)\n",
        "\n",
        "    def load_checkpoint(self, filename):\n",
        "        # Loads dictionary\n",
        "        checkpoint = torch.load(filename)\n",
        "\n",
        "        # Restore state for model and optimizer\n",
        "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "        self.total_epochs = checkpoint['epoch']\n",
        "        self.losses = checkpoint['loss']\n",
        "        self.val_losses = checkpoint['val_loss']\n",
        "\n",
        "        self.model.train() # always use TRAIN for resuming training\n",
        "\n",
        "    def predict(self, x):\n",
        "        # Set is to evaluation mode for predictions\n",
        "        self.model.eval()\n",
        "        # Takes aNumpy input and make it a float tensor\n",
        "        x_tensor = torch.as_tensor(x).float()\n",
        "        # Send input to device and uses model for prediction\n",
        "        y_hat_tensor = self.model(x_tensor.to(self.device))\n",
        "        # Set it back to train mode\n",
        "        self.model.train()\n",
        "        # Detaches it, brings it to CPU and back to Numpy\n",
        "        return y_hat_tensor.detach().cpu().numpy()\n",
        "\n",
        "    def count_parameters(self):\n",
        "      return sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n",
        "\n",
        "    def plot_losses(self):\n",
        "        fig = plt.figure(figsize=(10, 4))\n",
        "        plt.plot(self.losses, label='Training Loss', c='b')\n",
        "        plt.plot(self.val_losses, label='Validation Loss', c='r')\n",
        "        plt.yscale('log')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        return fig\n",
        "\n",
        "    @staticmethod\n",
        "    def _visualize_tensors(axs, x, y=None, yhat=None, layer_name='', title=None):\n",
        "        # The number of images is the number of subplots in a row\n",
        "        n_images = len(axs)\n",
        "        # Gets max and min values for scaling the grayscale\n",
        "        minv, maxv = np.min(x[:n_images]), np.max(x[:n_images])\n",
        "        # For each image\n",
        "        for j, image in enumerate(x[:n_images]):\n",
        "            ax = axs[j]\n",
        "            # Sets title, labels, and removes ticks\n",
        "            if title is not None:\n",
        "                ax.set_title(f'{title} #{j}', fontsize=12)\n",
        "            shp = np.atleast_2d(image).shape\n",
        "            ax.set_ylabel(\n",
        "                f'{layer_name}\\n{shp[0]}x{shp[1]}',\n",
        "                rotation=0, labelpad=40\n",
        "            )\n",
        "            xlabel1 = '' if y is None else f'\\nLabel: {y[j]}'\n",
        "            xlabel2 = '' if yhat is None else f'\\nPredicted: {yhat[j]}'\n",
        "            xlabel = f'{xlabel1}{xlabel2}'\n",
        "            if len(xlabel):\n",
        "                ax.set_xlabel(xlabel, fontsize=12)\n",
        "            ax.set_xticks([])\n",
        "            ax.set_yticks([])\n",
        "\n",
        "            # Plots weight as an image\n",
        "            ax.imshow(\n",
        "                np.atleast_2d(image.squeeze()),\n",
        "                cmap='gray',\n",
        "                vmin=minv,\n",
        "                vmax=maxv\n",
        "            )\n",
        "        return\n",
        "\n",
        "    def visualize_filters(self, layer_name, **kwargs):\n",
        "        try:\n",
        "            # Gets the layer object from the model\n",
        "            layer = self.model\n",
        "            for name in layer_name.split('.'):\n",
        "                layer = getattr(layer, name)\n",
        "            # We are only looking at filters for 2D convolutions\n",
        "            if isinstance(layer, nn.Conv2d):\n",
        "                # Takes the weight information\n",
        "                weights = layer.weight.data.cpu().numpy()\n",
        "                # weights -> (channels_out (filter), channels_in, H, W)\n",
        "                n_filters, n_channels, _, _ = weights.shape\n",
        "\n",
        "                # Builds a figure\n",
        "                size = (2 * n_channels + 2, 2 * n_filters)\n",
        "                fig, axes = plt.subplots(n_filters, n_channels,\n",
        "                                        figsize=size)\n",
        "                axes = np.atleast_2d(axes)\n",
        "                axes = axes.reshape(n_filters, n_channels)\n",
        "                # For each channel_out (filter)\n",
        "                for i in range(n_filters):\n",
        "                    Architecture._visualize_tensors(\n",
        "                        axes[i, :],\n",
        "                        weights[i],\n",
        "                        layer_name=f'Filter #{i}',\n",
        "                        title='Channel'\n",
        "                    )\n",
        "\n",
        "                for ax in axes.flat:\n",
        "                    ax.label_outer()\n",
        "\n",
        "                fig.tight_layout()\n",
        "                return fig\n",
        "        except AttributeError:\n",
        "            return\n",
        "\n",
        "    def attach_hooks(self, layers_to_hook, hook_fn=None):\n",
        "        # Clear any previous values\n",
        "        self.visualization = {}\n",
        "        # Creates the dictionary to map layer objects to their names\n",
        "        modules = list(self.model.named_modules())\n",
        "        layer_names = {layer: name for name, layer in modules[1:]}\n",
        "\n",
        "        if hook_fn is None:\n",
        "            # Hook function to be attached to the forward pass\n",
        "            def hook_fn(layer, inputs, outputs):\n",
        "                # Gets the layer name\n",
        "                name = layer_names[layer]\n",
        "                # Detaches outputs\n",
        "                values = outputs.detach().cpu().numpy()\n",
        "                # Since the hook function may be called multiple times\n",
        "                # for example, if we make predictions for multiple mini-batches\n",
        "                # it concatenates the results\n",
        "                if self.visualization[name] is None:\n",
        "                    self.visualization[name] = values\n",
        "                else:\n",
        "                    self.visualization[name] = np.concatenate([self.visualization[name], values])\n",
        "\n",
        "        for name, layer in modules:\n",
        "            # If the layer is in our list\n",
        "            if name in layers_to_hook:\n",
        "                # Initializes the corresponding key in the dictionary\n",
        "                self.visualization[name] = None\n",
        "                # Register the forward hook and keep the handle in another dict\n",
        "                self.handles[name] = layer.register_forward_hook(hook_fn)\n",
        "\n",
        "    def remove_hooks(self):\n",
        "        # Loops through all hooks and removes them\n",
        "        for handle in self.handles.values():\n",
        "            handle.remove()\n",
        "        # Clear the dict, as all hooks have been removed\n",
        "        self.handles = {}\n",
        "\n",
        "    def visualize_outputs(self, layers, n_images=10, y=None, yhat=None):\n",
        "        layers = filter(lambda l: l in self.visualization.keys(), layers)\n",
        "        layers = list(layers)\n",
        "        shapes = [self.visualization[layer].shape for layer in layers]\n",
        "        n_rows = [shape[1] if len(shape) == 4 else 1\n",
        "                  for shape in shapes]\n",
        "        total_rows = np.sum(n_rows)\n",
        "\n",
        "        fig, axes = plt.subplots(total_rows, n_images,\n",
        "                                figsize=(1.5*n_images, 1.5*total_rows))\n",
        "        axes = np.atleast_2d(axes).reshape(total_rows, n_images)\n",
        "\n",
        "        # Loops through the layers, one layer per row of subplots\n",
        "        row = 0\n",
        "        for i, layer in enumerate(layers):\n",
        "            start_row = row\n",
        "            # Takes the produced feature maps for that layer\n",
        "            output = self.visualization[layer]\n",
        "\n",
        "            is_vector = len(output.shape) == 2\n",
        "\n",
        "            for j in range(n_rows[i]):\n",
        "                Architecture._visualize_tensors(\n",
        "                    axes[row, :],\n",
        "                    output if is_vector else output[:, j].squeeze(),\n",
        "                    y,\n",
        "                    yhat,\n",
        "                    layer_name=layers[i] \\\n",
        "                              if is_vector \\\n",
        "                              else f'{layers[i]}\\nfil#{row-start_row}',\n",
        "                    title='Image' if (row == 0) else None\n",
        "                )\n",
        "                row += 1\n",
        "\n",
        "        for ax in axes.flat:\n",
        "            ax.label_outer()\n",
        "\n",
        "        plt.tight_layout()\n",
        "        return fig\n",
        "\n",
        "    def correct(self, x, y, threshold=.5):\n",
        "        self.model.eval()\n",
        "        yhat = self.model(x.to(self.device))\n",
        "        y = y.to(self.device)\n",
        "        self.model.train()\n",
        "\n",
        "        # We get the size of the batch and the number of classes\n",
        "        # (only 1, if it is binary)\n",
        "        n_samples, n_dims = yhat.shape\n",
        "        if n_dims > 1:\n",
        "            # In a multiclass classification, the biggest logit\n",
        "            # always wins, so we don't bother getting probabilities\n",
        "\n",
        "            # This is PyTorch's version of argmax,\n",
        "            # but it returns a tuple: (max value, index of max value)\n",
        "            _, predicted = torch.max(yhat, 1)\n",
        "        else:\n",
        "            n_dims += 1\n",
        "            # In binary classification, we NEED to check if the\n",
        "            # last layer is a sigmoid (and then it produces probs)\n",
        "            if isinstance(self.model, nn.Sequential) and \\\n",
        "              isinstance(self.model[-1], nn.Sigmoid):\n",
        "                predicted = (yhat > threshold).long()\n",
        "            # or something else (logits), which we need to convert\n",
        "            # using a sigmoid\n",
        "            else:\n",
        "                predicted = (F.sigmoid(yhat) > threshold).long()\n",
        "\n",
        "        # How many samples got classified correctly for each class\n",
        "        result = []\n",
        "        for c in range(n_dims):\n",
        "            n_class = (y == c).sum().item()\n",
        "            n_correct = (predicted[y == c] == c).sum().item()\n",
        "            result.append((n_correct, n_class))\n",
        "        return torch.tensor(result)\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def loader_apply(loader, func, reduce='sum'):\n",
        "        results = [func(x, y) for i, (x, y) in enumerate(loader)]\n",
        "        results = torch.stack(results, axis=0)\n",
        "\n",
        "        if reduce == 'sum':\n",
        "            results = results.sum(axis=0)\n",
        "        elif reduce == 'mean':\n",
        "            results = results.float().mean(axis=0)\n",
        "\n",
        "        return results\n",
        "\n",
        "    @staticmethod\n",
        "    def statistics_per_channel(images, labels):\n",
        "        # NCHW\n",
        "        n_samples, n_channels, n_height, n_weight = images.size()\n",
        "        # Flatten HW into a single dimension\n",
        "        flatten_per_channel = images.reshape(n_samples, n_channels, -1)\n",
        "\n",
        "        # Computes statistics of each image per channel\n",
        "        # Average pixel value per channel\n",
        "        # (n_samples, n_channels)\n",
        "        means = flatten_per_channel.mean(axis=2)\n",
        "        # Standard deviation of pixel values per channel\n",
        "        # (n_samples, n_channels)\n",
        "        stds = flatten_per_channel.std(axis=2)\n",
        "\n",
        "        # Adds up statistics of all images in a mini-batch\n",
        "        # (1, n_channels)\n",
        "        sum_means = means.sum(axis=0)\n",
        "        sum_stds = stds.sum(axis=0)\n",
        "        # Makes a tensor of shape (1, n_channels)\n",
        "        # with the number of samples in the mini-batch\n",
        "        n_samples = torch.tensor([n_samples]*n_channels).float()\n",
        "\n",
        "        # Stack the three tensors on top of one another\n",
        "        # (3, n_channels)\n",
        "        return torch.stack([n_samples, sum_means, sum_stds], axis=0)\n",
        "\n",
        "    @staticmethod\n",
        "    def make_normalizer(loader):\n",
        "        total_samples, total_means, total_stds = Architecture.loader_apply(loader, Architecture.statistics_per_channel)\n",
        "        norm_mean = total_means / total_samples\n",
        "        norm_std = total_stds / total_samples\n",
        "        return Normalize(mean=norm_mean, std=norm_std)\n",
        "\n",
        "    def lr_range_test(self, data_loader, end_lr, num_iter=100, step_mode='exp', alpha=0.05, ax=None):\n",
        "        # Since the test updates both model and optimizer we need to store\n",
        "        # their initial states to restore them in the end\n",
        "        previous_states = {'model': deepcopy(self.model.state_dict()),\n",
        "                          'optimizer': deepcopy(self.optimizer.state_dict())}\n",
        "        # Retrieves the learning rate set in the optimizer\n",
        "        start_lr = self.optimizer.state_dict()['param_groups'][0]['lr']\n",
        "\n",
        "        # Builds a custom function and corresponding scheduler\n",
        "        lr_fn = make_lr_fn(start_lr, end_lr, num_iter)\n",
        "        scheduler = LambdaLR(self.optimizer, lr_lambda=lr_fn)\n",
        "\n",
        "        # Variables for tracking results and iterations\n",
        "        tracking = {'loss': [], 'lr': []}\n",
        "        iteration = 0\n",
        "\n",
        "        # If there are more iterations than mini-batches in the data loader,\n",
        "        # it will have to loop over it more than once\n",
        "        while (iteration < num_iter):\n",
        "            # That's the typical mini-batch inner loop\n",
        "            for x_batch, y_batch in data_loader:\n",
        "                x_batch = x_batch.to(self.device)\n",
        "                y_batch = y_batch.to(self.device)\n",
        "                # Step 1\n",
        "                yhat = self.model(x_batch)\n",
        "                # Step 2\n",
        "                loss = self.loss_fn(yhat, y_batch)\n",
        "                # Step 3\n",
        "                loss.backward()\n",
        "\n",
        "                # Here we keep track of the losses (smoothed)\n",
        "                # and the learning rates\n",
        "                tracking['lr'].append(scheduler.get_last_lr()[0])\n",
        "                if iteration == 0:\n",
        "                    tracking['loss'].append(loss.item())\n",
        "                else:\n",
        "                    prev_loss = tracking['loss'][-1]\n",
        "                    smoothed_loss = alpha * loss.item() + (1-alpha) * prev_loss\n",
        "                    tracking['loss'].append(smoothed_loss)\n",
        "\n",
        "                iteration += 1\n",
        "                # Number of iterations reached\n",
        "                if iteration == num_iter:\n",
        "                    break\n",
        "\n",
        "                # Step 4\n",
        "                self.optimizer.step()\n",
        "                scheduler.step()\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "        # Restores the original states\n",
        "        self.optimizer.load_state_dict(previous_states['optimizer'])\n",
        "        self.model.load_state_dict(previous_states['model'])\n",
        "\n",
        "        if ax is None:\n",
        "            fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
        "        else:\n",
        "            fig = ax.get_figure()\n",
        "        ax.plot(tracking['lr'], tracking['loss'])\n",
        "        if step_mode == 'exp':\n",
        "            ax.set_xscale('log')\n",
        "        ax.set_xlabel('Learning Rate')\n",
        "        ax.set_ylabel('Loss')\n",
        "        fig.tight_layout()\n",
        "        return tracking, fig\n",
        "\n",
        "    def set_optimizer(self, optimizer):\n",
        "        self.optimizer = optimizer"
      ],
      "metadata": {
        "id": "8snON0VfNXTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Dataset\n",
        "\n",
        "dataset_iracing/\n",
        "\n",
        " - reta\n",
        " - freada_apex\n",
        " - saida_curva"
      ],
      "metadata": {
        "id": "cOaHaWUUNdJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/MyDrive/Colab_Notebooks/Aulas_Doutorado/Iracing_Classification/dataset_iracing\n",
        "\n",
        "# To list contents of the current directory\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cfAA0GsS729",
        "outputId": "c317b71c-1fc5-4602-81c4-b9a540bd0ecf"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Colab_Notebooks/Aulas_Doutorado/Iracing_Classification/dataset_iracing\n",
            "carro_a_frente\tcurva_apex\t     freada  pista_livre  saida_curva\n",
            "carro_atras\tdisputa_lado_a_lado  outros  reta\t  screenshots\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGFEFfXtUuB9",
        "outputId": "2fd18b80-bb2f-4e16-ed7d-703bbbb89ff8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "carro_a_frente\tcurva_apex\t     freada  pista_livre  saida_curva\n",
            "carro_atras\tdisputa_lado_a_lado  outros  reta\t  screenshots\n",
            "/content/drive/MyDrive/Colab_Notebooks/Aulas_Doutorado/Iracing_Classification/dataset_iracing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: abra as imagens da pasta carro_atras\n",
        "\n",
        "from IPython.display import display\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "folder_path = 'carro_atras'  # Replace with the actual folder name\n",
        "\n",
        "# List all files in the folder\n",
        "image_files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
        "\n",
        "# Display each image\n",
        "for image_file in image_files:\n",
        "  image_path = os.path.join(folder_path, image_file)\n",
        "  try:\n",
        "    img = Image.open(image_path)\n",
        "    display(img)\n",
        "  except IOError:\n",
        "    print(f\"Could not open or display file: {image_file}\")\n"
      ],
      "metadata": {
        "id": "SAdG7yojNfnY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}